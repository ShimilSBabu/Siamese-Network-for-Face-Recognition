{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMJX/z8DZ1Gv5agJad56ER1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShimilSBabu/Siamese-Network-for-Face-Recognition/blob/main/siamese_network_fetch_olivetti_faces.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libs"
      ],
      "metadata": {
        "id": "wGMFGjmSkv0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "from numpy.random import RandomState\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten, Dropout, GlobalAveragePooling2D, Lambda\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as k"
      ],
      "metadata": {
        "id": "M7ovXXB4ku-P"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Defenition"
      ],
      "metadata": {
        "id": "cnVC4yzEj36Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2jXyONkBiMQN"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    inputs = Input((64, 64, 1))\n",
        "    x = Conv2D(96, (11, 11), padding=\"same\", activation=\"relu\")(inputs)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    x = Conv2D(256, (5, 5), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    x = Conv2D(384, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    pooledOutput = GlobalAveragePooling2D()(x)\n",
        "    pooledOutput = Dense(1024)(pooledOutput)\n",
        "    outputs = Dense(128)(pooledOutput)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extractor"
      ],
      "metadata": {
        "id": "uzNZDJFhj-HB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor = create_model()\n",
        "imgA = Input(shape=(64, 64, 1))\n",
        "imgB = Input(shape=(64, 64, 1))\n",
        "featA = feature_extractor(imgA)\n",
        "featB = feature_extractor(imgB)"
      ],
      "metadata": {
        "id": "_WZvFE_Gj-aw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to Calculate Euclidian Distance"
      ],
      "metadata": {
        "id": "WuF0cMohkN4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_distance(vectors):\n",
        "    (featA, featB) = vectors\n",
        "    sum_squared = k.sum(k.square(featA - featB), axis=1, keepdims=True)\n",
        "    return k.sqrt(k.maximum(sum_squared, k.epsilon()))\n",
        "\n",
        "distance = Lambda(euclidean_distance)([featA, featB])\n",
        "outputs = Dense(1, activation=\"sigmoid\")(distance)\n",
        "model = Model(inputs=[imgA, imgB], outputs=outputs)"
      ],
      "metadata": {
        "id": "JOtjbk7JkTuv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compiling the Model"
      ],
      "metadata": {
        "id": "k06mCVm7kZnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "zWbEYNs-kclw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the Dataset"
      ],
      "metadata": {
        "id": "bPC07kY-xS70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rng = RandomState(0)\n",
        "images_dataset, labels_dataset = fetch_olivetti_faces(return_X_y=True, shuffle=True, random_state=rng)\n",
        "n_samples, n_features = images_dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPECotrvxXAl",
        "outputId": "1f90cab6-8b79-4d8f-9c18-15c739c1572c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading Olivetti faces from https://ndownloader.figshare.com/files/5976027 to /root/scikit_learn_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resizing the Dataset\n",
        "The fetched dataset *images_dataset* has size 400\\*4064. We need to resize it to 400\\*64\\*64 to give it as input to our model's training function."
      ],
      "metadata": {
        "id": "eyfyAIdyJrYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "faces_resized = []\n",
        "for num in range(len(images_dataset)):\n",
        "  faces_resized.append(cv2.resize(images_dataset[num], dsize=(64, 64)))"
      ],
      "metadata": {
        "id": "OMe1L14W4Mgo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Pairs Generation"
      ],
      "metadata": {
        "id": "NP2FkVT4yKgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_train_image_pairs(images_dataset, labels_dataset):\n",
        "    unique_labels = np.unique(labels_dataset)\n",
        "    label_wise_indices = dict()\n",
        "    for label in unique_labels:\n",
        "        label_wise_indices.setdefault(label,\n",
        "                                      [index for index, curr_label in enumerate(labels_dataset) if\n",
        "                                       label == curr_label])\n",
        "    \n",
        "    pair_images = []\n",
        "    pair_labels = []\n",
        "    for index, image in enumerate(images_dataset):\n",
        "        pos_indices = label_wise_indices.get(labels_dataset[index])\n",
        "        pos_image = images_dataset[np.random.choice(pos_indices)]\n",
        "        \n",
        "        image = cv2.resize(image, dsize=(64, 64))\n",
        "        \n",
        "        pair_images.append((image, pos_image))\n",
        "        pair_labels.append(1)\n",
        "\n",
        "        neg_indices = np.where(labels_dataset != labels_dataset[index])\n",
        "        neg_image = images_dataset[np.random.choice(neg_indices[0])]\n",
        "        pair_images.append((image, neg_image))\n",
        "        pair_labels.append(0)\n",
        "    return np.array(pair_images), np.array(pair_labels)"
      ],
      "metadata": {
        "id": "4gpUyj5EyIr1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "iUWNGG4-voZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images_pair, labels_pair = generate_train_image_pairs(faces_resized, labels_dataset)\n",
        "history = model.fit([images_pair[:, 0], images_pair[:, 1]], labels_pair[:],validation_split=0.1,batch_size=64,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kZVbsdeyivH",
        "outputId": "e1154ee4-0fe2-45bb-984b-b2bcdefd8c11"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "12/12 [==============================] - 12s 164ms/step - loss: 0.6939 - accuracy: 0.5000 - val_loss: 0.6503 - val_accuracy: 0.6000\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 1s 88ms/step - loss: 0.6716 - accuracy: 0.5000 - val_loss: 0.6576 - val_accuracy: 0.6250\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 1s 88ms/step - loss: 0.6734 - accuracy: 0.5000 - val_loss: 0.6629 - val_accuracy: 0.6500\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 1s 87ms/step - loss: 0.6634 - accuracy: 0.5097 - val_loss: 0.6467 - val_accuracy: 0.6625\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 1s 88ms/step - loss: 0.6556 - accuracy: 0.5069 - val_loss: 0.6712 - val_accuracy: 0.7000\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 1s 88ms/step - loss: 0.6631 - accuracy: 0.5819 - val_loss: 0.6322 - val_accuracy: 0.6500\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 1s 88ms/step - loss: 0.6661 - accuracy: 0.5458 - val_loss: 0.6554 - val_accuracy: 0.6625\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 1s 88ms/step - loss: 0.6453 - accuracy: 0.5417 - val_loss: 0.6574 - val_accuracy: 0.6625\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 1s 88ms/step - loss: 0.6661 - accuracy: 0.6083 - val_loss: 0.6617 - val_accuracy: 0.6125\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 1s 90ms/step - loss: 0.6505 - accuracy: 0.5597 - val_loss: 0.6718 - val_accuracy: 0.5875\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 1s 92ms/step - loss: 0.6358 - accuracy: 0.5694 - val_loss: 0.6520 - val_accuracy: 0.6125\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 1s 88ms/step - loss: 0.6298 - accuracy: 0.5556 - val_loss: 0.6583 - val_accuracy: 0.6375\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 1s 88ms/step - loss: 0.6225 - accuracy: 0.6014 - val_loss: 0.6622 - val_accuracy: 0.6125\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 1s 88ms/step - loss: 0.6359 - accuracy: 0.5875 - val_loss: 0.6500 - val_accuracy: 0.6500\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 1s 88ms/step - loss: 0.6248 - accuracy: 0.5972 - val_loss: 0.6633 - val_accuracy: 0.6125\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 1s 88ms/step - loss: 0.6247 - accuracy: 0.6069 - val_loss: 0.6750 - val_accuracy: 0.6500\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 1s 88ms/step - loss: 0.6321 - accuracy: 0.5944 - val_loss: 0.6769 - val_accuracy: 0.6000\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 1s 88ms/step - loss: 0.6267 - accuracy: 0.6792 - val_loss: 0.6596 - val_accuracy: 0.6000\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 1s 88ms/step - loss: 0.6174 - accuracy: 0.6250 - val_loss: 0.6597 - val_accuracy: 0.6625\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 1s 89ms/step - loss: 0.6116 - accuracy: 0.6167 - val_loss: 0.6696 - val_accuracy: 0.6125\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 1s 88ms/step - loss: 0.6121 - accuracy: 0.6486 - val_loss: 0.6633 - val_accuracy: 0.6125\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 1s 89ms/step - loss: 0.6059 - accuracy: 0.6403 - val_loss: 0.6648 - val_accuracy: 0.6375\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 1s 90ms/step - loss: 0.6068 - accuracy: 0.6431 - val_loss: 0.6617 - val_accuracy: 0.6625\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 1s 88ms/step - loss: 0.6060 - accuracy: 0.6639 - val_loss: 0.6701 - val_accuracy: 0.6250\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 1s 88ms/step - loss: 0.6152 - accuracy: 0.6611 - val_loss: 0.6645 - val_accuracy: 0.6500\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 1s 88ms/step - loss: 0.6069 - accuracy: 0.6500 - val_loss: 0.6559 - val_accuracy: 0.6625\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 1s 88ms/step - loss: 0.5983 - accuracy: 0.7014 - val_loss: 0.6499 - val_accuracy: 0.6750\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 1s 90ms/step - loss: 0.5968 - accuracy: 0.6861 - val_loss: 0.6522 - val_accuracy: 0.6750\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 1s 88ms/step - loss: 0.5912 - accuracy: 0.6833 - val_loss: 0.6483 - val_accuracy: 0.6125\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 1s 89ms/step - loss: 0.6098 - accuracy: 0.7042 - val_loss: 0.6554 - val_accuracy: 0.6875\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 1s 89ms/step - loss: 0.6048 - accuracy: 0.6653 - val_loss: 0.6565 - val_accuracy: 0.6375\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 1s 89ms/step - loss: 0.5950 - accuracy: 0.6806 - val_loss: 0.6604 - val_accuracy: 0.5750\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 1s 97ms/step - loss: 0.6044 - accuracy: 0.6819 - val_loss: 0.6556 - val_accuracy: 0.6375\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 1s 92ms/step - loss: 0.5913 - accuracy: 0.7181 - val_loss: 0.6387 - val_accuracy: 0.6750\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 1s 95ms/step - loss: 0.5840 - accuracy: 0.7014 - val_loss: 0.6374 - val_accuracy: 0.7125\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 1s 90ms/step - loss: 0.6037 - accuracy: 0.6986 - val_loss: 0.6630 - val_accuracy: 0.6125\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 1s 90ms/step - loss: 0.5891 - accuracy: 0.7042 - val_loss: 0.6483 - val_accuracy: 0.6375\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 1s 89ms/step - loss: 0.5860 - accuracy: 0.6931 - val_loss: 0.6392 - val_accuracy: 0.7000\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 1s 89ms/step - loss: 0.5845 - accuracy: 0.7014 - val_loss: 0.6723 - val_accuracy: 0.6375\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 1s 89ms/step - loss: 0.5962 - accuracy: 0.6778 - val_loss: 0.6624 - val_accuracy: 0.6125\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 1s 89ms/step - loss: 0.5934 - accuracy: 0.6986 - val_loss: 0.6674 - val_accuracy: 0.6375\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 1s 89ms/step - loss: 0.5842 - accuracy: 0.7111 - val_loss: 0.6339 - val_accuracy: 0.7250\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 1s 89ms/step - loss: 0.5798 - accuracy: 0.7347 - val_loss: 0.6529 - val_accuracy: 0.6000\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 1s 90ms/step - loss: 0.5804 - accuracy: 0.7236 - val_loss: 0.6540 - val_accuracy: 0.6625\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 1s 90ms/step - loss: 0.5693 - accuracy: 0.7319 - val_loss: 0.6741 - val_accuracy: 0.6125\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 1s 89ms/step - loss: 0.5752 - accuracy: 0.7333 - val_loss: 0.6442 - val_accuracy: 0.6250\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 1s 92ms/step - loss: 0.5719 - accuracy: 0.7333 - val_loss: 0.6364 - val_accuracy: 0.6875\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 1s 90ms/step - loss: 0.5775 - accuracy: 0.7236 - val_loss: 0.6469 - val_accuracy: 0.6125\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 1s 90ms/step - loss: 0.5699 - accuracy: 0.7222 - val_loss: 0.6445 - val_accuracy: 0.5750\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 1s 90ms/step - loss: 0.5655 - accuracy: 0.7403 - val_loss: 0.6249 - val_accuracy: 0.6875\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 1s 90ms/step - loss: 0.5819 - accuracy: 0.7125 - val_loss: 0.6488 - val_accuracy: 0.6500\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 1s 90ms/step - loss: 0.5829 - accuracy: 0.7222 - val_loss: 0.6677 - val_accuracy: 0.6250\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 1s 90ms/step - loss: 0.5638 - accuracy: 0.7486 - val_loss: 0.6393 - val_accuracy: 0.6750\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 1s 91ms/step - loss: 0.5631 - accuracy: 0.7236 - val_loss: 0.6386 - val_accuracy: 0.6625\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 1s 90ms/step - loss: 0.5614 - accuracy: 0.7583 - val_loss: 0.6469 - val_accuracy: 0.6750\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 1s 90ms/step - loss: 0.5501 - accuracy: 0.7472 - val_loss: 0.6295 - val_accuracy: 0.6625\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 1s 93ms/step - loss: 0.5712 - accuracy: 0.7250 - val_loss: 0.6598 - val_accuracy: 0.6125\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 1s 91ms/step - loss: 0.5630 - accuracy: 0.7306 - val_loss: 0.6410 - val_accuracy: 0.6250\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 1s 91ms/step - loss: 0.5630 - accuracy: 0.7361 - val_loss: 0.6111 - val_accuracy: 0.6625\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 1s 91ms/step - loss: 0.5616 - accuracy: 0.7361 - val_loss: 0.6481 - val_accuracy: 0.6125\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 1s 92ms/step - loss: 0.5647 - accuracy: 0.7444 - val_loss: 0.6838 - val_accuracy: 0.5750\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 1s 97ms/step - loss: 0.5616 - accuracy: 0.7292 - val_loss: 0.6641 - val_accuracy: 0.6125\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 1s 96ms/step - loss: 0.5589 - accuracy: 0.7431 - val_loss: 0.6323 - val_accuracy: 0.6000\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 1s 92ms/step - loss: 0.5418 - accuracy: 0.7597 - val_loss: 0.6362 - val_accuracy: 0.6250\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 1s 91ms/step - loss: 0.5454 - accuracy: 0.7556 - val_loss: 0.6641 - val_accuracy: 0.5500\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 1s 91ms/step - loss: 0.5466 - accuracy: 0.7347 - val_loss: 0.6688 - val_accuracy: 0.5625\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 1s 92ms/step - loss: 0.5874 - accuracy: 0.6972 - val_loss: 0.6643 - val_accuracy: 0.5875\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 1s 92ms/step - loss: 0.5850 - accuracy: 0.7056 - val_loss: 0.6535 - val_accuracy: 0.6125\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 1s 92ms/step - loss: 0.5813 - accuracy: 0.7208 - val_loss: 0.6617 - val_accuracy: 0.6000\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 1s 93ms/step - loss: 0.5859 - accuracy: 0.7069 - val_loss: 0.6443 - val_accuracy: 0.6250\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 1s 91ms/step - loss: 0.5928 - accuracy: 0.6861 - val_loss: 0.6815 - val_accuracy: 0.5500\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 1s 93ms/step - loss: 0.5728 - accuracy: 0.7167 - val_loss: 0.6423 - val_accuracy: 0.6000\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 1s 92ms/step - loss: 0.5522 - accuracy: 0.7431 - val_loss: 0.6572 - val_accuracy: 0.5625\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 1s 92ms/step - loss: 0.5452 - accuracy: 0.7431 - val_loss: 0.6405 - val_accuracy: 0.6250\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 1s 92ms/step - loss: 0.5361 - accuracy: 0.7542 - val_loss: 0.6473 - val_accuracy: 0.5875\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 1s 93ms/step - loss: 0.5375 - accuracy: 0.7681 - val_loss: 0.6820 - val_accuracy: 0.5375\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 1s 92ms/step - loss: 0.5306 - accuracy: 0.7847 - val_loss: 0.6564 - val_accuracy: 0.5750\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 1s 93ms/step - loss: 0.5282 - accuracy: 0.7750 - val_loss: 0.6163 - val_accuracy: 0.6250\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 1s 93ms/step - loss: 0.5432 - accuracy: 0.7472 - val_loss: 0.6116 - val_accuracy: 0.6500\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 1s 93ms/step - loss: 0.5421 - accuracy: 0.7431 - val_loss: 0.6681 - val_accuracy: 0.5625\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 1s 93ms/step - loss: 0.5359 - accuracy: 0.7597 - val_loss: 0.6743 - val_accuracy: 0.5750\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 1s 92ms/step - loss: 0.5533 - accuracy: 0.7500 - val_loss: 0.6103 - val_accuracy: 0.6500\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 1s 93ms/step - loss: 0.5489 - accuracy: 0.7597 - val_loss: 0.6383 - val_accuracy: 0.6000\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 1s 94ms/step - loss: 0.5404 - accuracy: 0.7375 - val_loss: 0.6922 - val_accuracy: 0.5500\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 1s 93ms/step - loss: 0.5415 - accuracy: 0.7417 - val_loss: 0.6475 - val_accuracy: 0.6125\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 1s 93ms/step - loss: 0.5218 - accuracy: 0.7722 - val_loss: 0.6151 - val_accuracy: 0.5875\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 1s 93ms/step - loss: 0.5279 - accuracy: 0.7750 - val_loss: 0.6580 - val_accuracy: 0.5750\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 1s 93ms/step - loss: 0.5263 - accuracy: 0.7708 - val_loss: 0.6521 - val_accuracy: 0.6375\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 1s 95ms/step - loss: 0.5454 - accuracy: 0.7319 - val_loss: 0.6556 - val_accuracy: 0.5750\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 1s 94ms/step - loss: 0.5126 - accuracy: 0.7875 - val_loss: 0.6844 - val_accuracy: 0.5375\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 1s 93ms/step - loss: 0.5134 - accuracy: 0.7819 - val_loss: 0.6657 - val_accuracy: 0.5875\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 1s 94ms/step - loss: 0.5062 - accuracy: 0.7792 - val_loss: 0.6663 - val_accuracy: 0.6000\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 1s 94ms/step - loss: 0.5059 - accuracy: 0.7708 - val_loss: 0.6334 - val_accuracy: 0.5875\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 1s 94ms/step - loss: 0.5159 - accuracy: 0.7542 - val_loss: 0.6715 - val_accuracy: 0.5750\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 1s 100ms/step - loss: 0.5235 - accuracy: 0.7611 - val_loss: 0.6132 - val_accuracy: 0.6250\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 1s 101ms/step - loss: 0.5338 - accuracy: 0.7472 - val_loss: 0.6365 - val_accuracy: 0.6125\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 1s 105ms/step - loss: 0.5059 - accuracy: 0.7806 - val_loss: 0.6525 - val_accuracy: 0.5875\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.5002 - accuracy: 0.7875 - val_loss: 0.6861 - val_accuracy: 0.5750\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 1s 95ms/step - loss: 0.4928 - accuracy: 0.7972 - val_loss: 0.6899 - val_accuracy: 0.5250\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 1s 94ms/step - loss: 0.4996 - accuracy: 0.7778 - val_loss: 0.6663 - val_accuracy: 0.5750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Pairs Generation"
      ],
      "metadata": {
        "id": "YF37t_83IOKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_test_image_pairs(images_dataset, labels_dataset, image):\n",
        "    unique_labels = np.unique(labels_dataset)\n",
        "    label_wise_indices = dict()\n",
        "    for label in unique_labels:\n",
        "        label_wise_indices.setdefault(label,\n",
        "                                      [index for index, curr_label in enumerate(labels_dataset) if\n",
        "                                        label == curr_label])\n",
        "  \n",
        "    pair_images = []\n",
        "    pair_labels = []\n",
        "    for label, indices_for_label in label_wise_indices.items():\n",
        "        test_image = images_dataset[np.random.choice(indices_for_label)]\n",
        "        pair_images.append((image, test_image))\n",
        "        pair_labels.append(label)\n",
        "    return np.array(pair_images), np.array(pair_labels)"
      ],
      "metadata": {
        "id": "_3dSFgszIMfc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "6WMTLdILJO6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = faces_resized[92] # a random image as test image\n",
        "test_image_pairs, test_label_pairs = generate_test_image_pairs(faces_resized, labels_dataset, image) # produce an array of test image pairs and test label pairs\n",
        "\n",
        "# for each pair in the test image pair, predict the similarity between the images\n",
        "for index, pair in enumerate(test_image_pairs):\n",
        "    pair_image1 = np.expand_dims(pair[0], axis=-1)\n",
        "    pair_image1 = np.expand_dims(pair_image1, axis=0)\n",
        "    pair_image2 = np.expand_dims(pair[1], axis=-1)\n",
        "    pair_image2 = np.expand_dims(pair_image2, axis=0)\n",
        "    prediction = model.predict([pair_image1, pair_image2])[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brcAeykNJL9c",
        "outputId": "19ff371c-cb85-4014-bb0b-41d145464ff4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 323ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Credits :- Girija Shankar Behera\n",
        "\n",
        "https://medium.com/wicds/face-recognition-using-siamese-networks-84d6f2e54ea4"
      ],
      "metadata": {
        "id": "OsaAwHT7u9tr"
      }
    }
  ]
}